{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ``converters`` are currently experimental. It may not support operations including (but not limited to) Functions in ``torch.nn.functional`` that involved data dimension\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from dataset import *\n",
    "from utils import Transform3D, model_to_syncbn\n",
    "from models import ResNet18, ResNet50\n",
    "from acsconv.converters import ACSConverter, Conv2_5dConverter, Conv3dConverter\n",
    "\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "from medmnist import OrganMNIST3D\n",
    "\n",
    "from torchvision.models import resnet18, resnet50\n",
    "from torchvision.models import swin_v2_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/vemundlund/.medmnist/organmnist3d.npz\n",
      "Using downloaded and verified file: /Users/vemundlund/.medmnist/organmnist3d.npz\n",
      "Using downloaded and verified file: /Users/vemundlund/.medmnist/organmnist3d.npz\n",
      "Using downloaded and verified file: /Users/vemundlund/.medmnist/organmnist3d.npz\n",
      "==> Building and training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vemundlund/miniconda3/envs/vi_venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/vemundlund/miniconda3/envs/vi_venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "data_flag = 'organmnist3d'\n",
    "download = True\n",
    "\n",
    "DEVICE = 'cpu'\n",
    "NUM_EPOCHS = 25\n",
    "BATCH_SIZE = 16\n",
    "milestones = [0.5 * NUM_EPOCHS, 0.75 * NUM_EPOCHS]\n",
    "lr = 0.001\n",
    "gamma = 0.1\n",
    "\n",
    "output_root = './output3d'\n",
    "\n",
    "info = INFO[data_flag]\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "task = info['task']\n",
    "\n",
    "train_loader, train_loader_at_eval, val_loader, test_loader = extract_data_3d(data_flag, download, BATCH_SIZE)\n",
    "\n",
    "model = resnet18(pretrained=True)\n",
    "model.fc.out_features = n_classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, n_classes)\n",
    "model.name = 'resnet18'\n",
    "\n",
    "# model = resnet50(pretrained=True)\n",
    "# model.fc.out_features = n_classes\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_ftrs, n_classes)\n",
    "# model.name = 'resnet50'\n",
    "\n",
    "# model = swin_v2_t(pretrained=True)\n",
    "# model.head.out_features = n_classes\n",
    "# num_ftrs = model.head.in_features\n",
    "# model.head = nn.Linear(num_ftrs, n_classes)\n",
    "# model.name = 'resnet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 61/61 [00:28<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with batches\n",
      "Epoch loss 2.4378304461963842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 61/61 [00:08<00:00,  6.97it/s]\n",
      "test: 100%|██████████| 61/61 [00:08<00:00,  6.92it/s]\n",
      "test: 100%|██████████| 61/61 [00:09<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_best_auc: 0.8579103087707044\n",
      "cur_best_epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 61/61 [00:27<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with batches\n",
      "Epoch loss 2.0045319541555937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 61/61 [00:08<00:00,  6.93it/s]\n",
      "test: 100%|██████████| 61/61 [00:08<00:00,  7.00it/s]\n",
      "test: 100%|██████████| 61/61 [00:08<00:00,  7.05it/s]\n",
      "train: 100%|██████████| 61/61 [00:27<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with batches\n",
      "Epoch loss 1.9154191837936152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 61/61 [00:09<00:00,  6.62it/s]\n",
      "test: 100%|██████████| 61/61 [00:08<00:00,  6.88it/s]\n",
      "test: 100%|██████████| 61/61 [00:09<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_best_auc: 0.9006363303784777\n",
      "cur_best_epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  67%|██████▋   | 41/61 [00:19<00:09,  2.06it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/vemundlund/Code/vi-miniproject/main_mnist3D.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vemundlund/Code/vi-miniproject/main_mnist3D.ipynb#W3sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m iteration \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vemundlund/Code/vi-miniproject/main_mnist3D.ipynb#W3sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vemundlund/Code/vi-miniproject/main_mnist3D.ipynb#W3sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, train_loader, task, criterion, optimizer, DEVICE, writer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vemundlund/Code/vi-miniproject/main_mnist3D.ipynb#W3sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     train_metrics \u001b[39m=\u001b[39m test(model, train_evaluator, train_loader_at_eval, task, criterion, DEVICE, \u001b[39m'\u001b[39m\u001b[39mmodel3d\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vemundlund/Code/vi-miniproject/main_mnist3D.ipynb#W3sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     val_metrics \u001b[39m=\u001b[39m test(model, train_evaluator, train_loader_at_eval, task, criterion, DEVICE, \u001b[39m'\u001b[39m\u001b[39mmodel3d\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Code/vi-miniproject/dataset.py:99\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, task, criterion, optimizer, device, writer)\u001b[0m\n\u001b[1;32m     96\u001b[0m     writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m'\u001b[39m\u001b[39mtrain_loss_logs\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m.\u001b[39mitem(), iteration)\n\u001b[1;32m     97\u001b[0m     iteration \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 99\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    100\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    101\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone with batches\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_venv/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_venv/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "conv = 'Conv3d'\n",
    "pretrained_3d = 'i3d'\n",
    "model_flag = 'resnet18'\n",
    "\n",
    "# if model_flag == 'resnet18':\n",
    "#     model = ResNet18(in_channels=n_channels, num_classes=n_classes)\n",
    "# elif model_flag == 'resnet50':\n",
    "#     model = ResNet50(in_channels=n_channels, num_classes=n_classes)\n",
    "# else:\n",
    "#     raise NotImplementedError\n",
    "\n",
    "if conv=='ACSConv':\n",
    "    model = model_to_syncbn(ACSConverter(model))\n",
    "if conv=='Conv2_5d':\n",
    "    model = model_to_syncbn(Conv2_5dConverter(model))\n",
    "if conv=='Conv3d':\n",
    "    if pretrained_3d == 'i3d':\n",
    "        model = model_to_syncbn(Conv3dConverter(model, i3d_repeat_axis=-3))\n",
    "    else:\n",
    "        model = model_to_syncbn(Conv3dConverter(model, i3d_repeat_axis=None))\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "train_evaluator = medmnist.Evaluator(data_flag, 'train')\n",
    "val_evaluator = medmnist.Evaluator(data_flag, 'val')\n",
    "test_evaluator = medmnist.Evaluator(data_flag, 'test')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
    "\n",
    "logs = ['loss', 'auc', 'acc']\n",
    "train_logs = ['train_'+log for log in logs]\n",
    "val_logs = ['val_'+log for log in logs]\n",
    "test_logs = ['test_'+log for log in logs]\n",
    "log_dict = OrderedDict.fromkeys(train_logs+val_logs+test_logs, 0)\n",
    "\n",
    "writer = SummaryWriter(log_dir=os.path.join(output_root, 'Tensorboard_Results_3D'))\n",
    "\n",
    "best_auc = 0\n",
    "best_epoch = 0\n",
    "best_model = deepcopy(model)\n",
    "tb_twod = False\n",
    "\n",
    "global iteration\n",
    "iteration = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = train(model, train_loader, task, criterion, optimizer, DEVICE, writer)\n",
    "\n",
    "    train_metrics = test(model, train_evaluator, train_loader_at_eval, task, criterion, DEVICE, 'model3d')\n",
    "    val_metrics = test(model, train_evaluator, train_loader_at_eval, task, criterion, DEVICE, 'model3d')\n",
    "    test_metrics = test(model, train_evaluator, train_loader_at_eval, task, criterion, DEVICE, 'model3d')\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    for i, key in enumerate(train_logs):\n",
    "        log_dict[key] = train_metrics[i]\n",
    "    for i, key in enumerate(val_logs):\n",
    "        log_dict[key] = val_metrics[i]\n",
    "    for i, key in enumerate(test_logs):\n",
    "        log_dict[key] = test_metrics[i]\n",
    "\n",
    "    for key, value in log_dict.items():\n",
    "        writer.add_scalar(key, value, epoch)\n",
    "        \n",
    "    cur_auc = val_metrics[1]\n",
    "    if cur_auc > best_auc:\n",
    "        best_epoch = epoch\n",
    "        best_auc = cur_auc\n",
    "        best_model = deepcopy(model)\n",
    "\n",
    "        print('cur_best_auc:', best_auc)\n",
    "        print('cur_best_epoch', best_epoch)\n",
    "\n",
    "state = {\n",
    "    'net': model.state_dict(),\n",
    "}\n",
    "\n",
    "path = os.path.join(output_root, 'best_model.pth')\n",
    "torch.save(state, path)\n",
    "\n",
    "train_metrics = test(model, train_evaluator, train_loader_at_eval, task, criterion, DEVICE, 'model3d')\n",
    "val_metrics = test(model, train_evaluator, train_loader_at_eval, task, criterion, DEVICE, 'model3d')\n",
    "test_metrics = test(model, train_evaluator, train_loader_at_eval, task, criterion, DEVICE, 'model3d')\n",
    "\n",
    "train_log = 'train  auc: %.5f  acc: %.5f\\n' % (train_metrics[1], train_metrics[2])\n",
    "val_log = 'val  auc: %.5f  acc: %.5f\\n' % (val_metrics[1], val_metrics[2])\n",
    "test_log = 'test  auc: %.5f  acc: %.5f\\n' % (test_metrics[1], test_metrics[2])\n",
    "\n",
    "log = '%s\\n' % (data_flag) + train_log + val_log + test_log + '\\n'\n",
    "print(log)\n",
    "\n",
    "with open(os.path.join(output_root, '%s_log.txt' % (data_flag)), 'a') as f:\n",
    "    f.write(log)        \n",
    "        \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No known TensorBoard instances running.\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vi_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
